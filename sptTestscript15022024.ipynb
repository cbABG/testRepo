{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chandan.bhardwaj\\AppData\\Local\\Temp\\ipykernel_23684\\440697630.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load configuration from YAML file\n",
    "with open('configTesting15022024.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "proxies = {'http': config['proxies']['http']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_year(date_str):\n",
    "    \"\"\"Parse date string and adjust the year.\"\"\"\n",
    "    today = datetime.today()\n",
    "    month, day = map(int, date_str.split('/'))\n",
    "    year = today.year if month <= today.month else today.year - 1\n",
    "    return datetime(year=year, month=month, day=day).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch and process data for Paraffin (Brent-Oil): 403 Client Error: Forbidden for url: https://in.investing.com/commodities/brent-oil-historical-data\n",
      "Failed to fetch and process data for Crude Oil: 403 Client Error: Forbidden for url: https://in.investing.com/commodities/brent-oil-historical-data\n",
      "Failed to fetch and process data for Diesel: 403 Client Error: Forbidden for url: https://www.goodreturns.in/diesel-price-in-mumbai.html\n",
      "Failed to fetch and process data for RMB_to_INR: 403 Client Error: Forbidden for url: https://in.investing.com/currencies/cny-inr-historical-data\n",
      "Failed to fetch and process data for USD_to_INR: 403 Client Error: Forbidden for url: https://in.investing.com/currencies/usd-inr-historical-data\n",
      "All data saved to combined_commodities_data.csv.\n"
     ]
    }
   ],
   "source": [
    "def fetch_commodity_data(website_config):\n",
    "    \"\"\"Fetch and process commodity data from a given website configuration.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(website_config['url'], proxies=proxies)\n",
    "        response.raise_for_status()  # This will raise an exception for HTTP error codes\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        data_rows = []\n",
    "        parent = soup.find(\"ul\", class_='zwd_table no_select').findAll(\"li\")\n",
    "        for ele in parent:\n",
    "            row_data = [p.get_text() for p in ele.findAll(\"p\")]\n",
    "            if row_data:  # Ensure row_data is not empty\n",
    "                data_rows.append(row_data)\n",
    "        \n",
    "        if data_rows:\n",
    "            df = pd.DataFrame(data_rows[1:], columns=data_rows[0])\n",
    "            df['Date'] = df['Date'].apply(find_year)\n",
    "            df['Price'] = df['Price'].astype(float)\n",
    "            df['Product Name'] = website_config['product_name']\n",
    "            df['Type'] = website_config['type']\n",
    "            df['Currency'] = website_config['currency']\n",
    "            df['WebsiteName'] = website_config['WebsiteName']\n",
    "            df['QueryTimestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df['TableFetchTimestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            return df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch and process data for {website_config['product_name']}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of failure\n",
    "\n",
    "def run():\n",
    "    all_data_frames = []  # List to store all DataFrames\n",
    "    for website in config['websites']:\n",
    "        df = fetch_commodity_data(website)\n",
    "        if not df.empty:\n",
    "            all_data_frames.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    if all_data_frames:\n",
    "        combined_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "        # Save the combined DataFrame to a single CSV file\n",
    "        combined_csv_filename = \"combined_commodities_data.csv\"\n",
    "        combined_df.to_csv(combined_csv_filename, index=False)\n",
    "        print(f\"All data saved to {combined_csv_filename}.\")\n",
    "    else:\n",
    "        print(\"No data fetched.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is still work in progress!\n",
    "def fetch_commodity_data(website_config):\n",
    "    \"\"\"Fetches and processes commodity data based on website configuration.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(website_config['url'], proxies=proxies)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        data_rows = []\n",
    "        # Placeholder for actual data extraction logic\n",
    "        parent = soup.find(\"ul\", class_='zwd_table no_select').findAll(\"li\")\n",
    "        for ele in parent:\n",
    "            row_data = [p.get_text() for p in ele.findAll(\"p\")]\n",
    "            if row_data:\n",
    "                data_rows.append(row_data)\n",
    "        \n",
    "        if data_rows:\n",
    "            df = pd.DataFrame(data_rows[1:], columns=['Date', 'Price', 'Open', 'High', 'Low', 'Volume', 'ChgPerc'])\n",
    "            df['Date'] = df['Date'].apply(lambda x: find_year(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            df['ProductName'] = website_config['product_name']\n",
    "            df['Type'] = website_config['type']\n",
    "            df['Currency'] = website_config['currency']\n",
    "            df['WebsiteName'] = website_config['WebsiteName']\n",
    "            df['QueryTimestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df['TableFetchTimestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            # Placeholder for USD_INR and RMB_INR conversion rates, adjust as necessary\n",
    "            df['USD_INR'] = 0  # Placeholder value\n",
    "            df['RMB_INR'] = 0  # Placeholder value\n",
    "            # Generating IdentifierKey\n",
    "            df['IdentifierKey'] = df.apply(lambda row: f\"{row['TableFetchTimestamp']}_{row['ProductName']}_{row['WebsiteName']}\", axis=1)\n",
    "            \n",
    "            return df\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch and process data for {website_config['product_name']}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is still work in progress!\n",
    "def run():\n",
    "    all_data_frames = []\n",
    "    for website in config['websites']:\n",
    "        df = fetch_commodity_data(website)\n",
    "        if not df.empty:\n",
    "            all_data_frames.append(df)\n",
    "\n",
    "    if all_data_frames:\n",
    "        combined_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "        combined_csv_filename = \"combined_commodities_data.csv\"\n",
    "        combined_df.to_csv(combined_csv_filename, index=False)\n",
    "        print(f\"All data saved to {combined_csv_filename}.\")\n",
    "    else:\n",
    "        print(\"No data fetched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'combined_commodities_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# this is still work in progress!\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m, in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_data_frames, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m     combined_csv_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_commodities_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mcombined_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_csv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll data saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_csv_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chandan.bhardwaj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chandan.bhardwaj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3961\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3950\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3952\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3953\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3954\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3958\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3959\u001b[0m )\n\u001b[1;32m-> 3961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3964\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chandan.bhardwaj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\chandan.bhardwaj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\chandan.bhardwaj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'combined_commodities_data.csv'"
     ]
    }
   ],
   "source": [
    "# this is still work in progress!\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    combined_data = []\n",
    "    for website in config['websites']:\n",
    "        df = fetch_commodity_data(website)\n",
    "        if not df.empty:\n",
    "            combined_data.append(df)\n",
    "\n",
    "    if combined_data:\n",
    "        combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "        combined_csv_filename = \"combined_commodities_data.csv\"\n",
    "        combined_df.to_csv(combined_csv_filename, index=False)\n",
    "        print(f\"Combined data saved to {combined_csv_filename}.\")\n",
    "    else:\n",
    "        print(\"No data fetched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to combined_commodities_data.csv.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_usd_inr_conversion_rate():\n",
    "    url = \"https://in.investing.com/currencies/usd-inr-historical-data\"\n",
    "    response = requests.get(url, proxies=proxies)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # You need to replace 'your-row-selector' with the actual selector that targets the rate\n",
    "    rows = soup.select('table.common-table.medium.js-table tr')\n",
    "    if rows:\n",
    "        latest_row = rows[1]  # Assuming the first row after the header has the latest rates\n",
    "        rate = latest_row.select_one('td:nth-child(2)').text  # Assuming the second column has the rate\n",
    "        return float(rate.replace(',', ''))\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_rmb_inr_conversion_rate():\n",
    "    url = \"https://in.investing.com/currencies/cny-inr-historical-data\"\n",
    "    response = requests.get(url, proxies=proxies)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    rows = soup.select('table.common-table.medium.js-table tr')\n",
    "    if rows:\n",
    "        latest_row = rows[1]\n",
    "        rate = latest_row.select_one('td:nth-child(2)').text\n",
    "        return float(rate.replace(',', ''))\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_commodity_data(website_config,usd_inr_rate, rmb_inr_rate):\n",
    "    \"\"\"Fetch and process commodity data based on website configuration.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(website_config['url'], proxies=proxies)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the data table, assuming 'li' elements under 'ul.zwd_table.no_select' contain the data rows\n",
    "        table_rows = soup.select('ul.zwd_table.no_select li')[1:]  # Skip the first row if it contains headers\n",
    "        \n",
    "        data_rows = []\n",
    "        for row in table_rows:\n",
    "            # Extract the text from each 'p' tag and strip it\n",
    "            columns = [col.get_text(strip=True) for col in row.find_all('p')]\n",
    "            # Now columns[0] should correspond to the 'Date' and columns[1] to the 'Price'\n",
    "            if len(columns) >= 2:  # Ensure there's at least Date and Price\n",
    "                date, price = columns[0], columns[1]\n",
    "                # Here you might need to convert date and price to the appropriate format\n",
    "                data_rows.append([\n",
    "                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # QueryTimestamp\n",
    "                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # TableFetchTimestamp\n",
    "                    price,  # Price from the page\n",
    "                    website_config['currency'],  # Currency from config\n",
    "                    'N/A', 'N/A', 'N/A', 'N/A', 'N/A',  # Other values as N/A or placeholders\n",
    "                    website_config['product_name'],  # ProductName from config\n",
    "                    website_config['type'],  # Type from config\n",
    "                    website_config['WebsiteName'],  # WebsiteName from config\n",
    "                    'N/A', 'N/A'  # USD_INR and RMB_INR as placeholders\n",
    "                ])\n",
    "        \n",
    "        # Construct DataFrame\n",
    "        df = pd.DataFrame(data_rows, columns=[\n",
    "            'QueryTimestamp', 'TableFetchTimestamp', 'Price', 'Currency', 'Open_', 'High', 'Low', \n",
    "            'Volume', 'ChgPerc', 'ProductName', 'Type', 'WebsiteName', 'USD_INR', 'RMB_INR'\n",
    "        ])\n",
    "        \n",
    "        # Assume that IdentifierKey is a combination of Timestamp, ProductName, and WebsiteName\n",
    "        df['IdentifierKey'] = df.apply(\n",
    "            lambda x: f\"{x['TableFetchTimestamp']}_{x['ProductName']}_{x['WebsiteName']}\", axis=1\n",
    "        )\n",
    "        df['USD_INR'] = usd_inr_rate\n",
    "        df['RMB_INR'] = rmb_inr_rate\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data for {website_config['product_name']}: {e}\")\n",
    "        return pd.DataFrame(columns=[\n",
    "            'QueryTimestamp', 'TableFetchTimestamp', 'Price', 'Currency', 'Open_', 'High', 'Low', \n",
    "            'Volume', 'ChgPerc', 'ProductName', 'Type', 'WebsiteName', 'USD_INR', 'RMB_INR', 'IdentifierKey'\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    usd_inr_rate = fetch_usd_inr_conversion_rate()\n",
    "    rmb_inr_rate = fetch_rmb_inr_conversion_rate()\n",
    "    combined_data = []\n",
    "    for website in config['websites']:\n",
    "        df = fetch_commodity_data(website,usd_inr_rate, rmb_inr_rate)\n",
    "        if not df.empty:\n",
    "            combined_data.append(df)\n",
    "\n",
    "    if combined_data:\n",
    "        combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "        combined_csv_filename = \"combined_commodities_data.csv\"\n",
    "        combined_df.to_csv(combined_csv_filename, index=False)\n",
    "        print(f\"Combined data saved to {combined_csv_filename}.\")\n",
    "    else:\n",
    "        print(\"No data fetched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to combined_commodities_data.csv.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_commodity_data(website_config, usd_inr_rate, rmb_inr_rate):\n",
    "    \"\"\"Fetch and process commodity data based on website configuration.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(website_config['url'], headers={'User-Agent': 'Mozilla/5.0'}, proxies=proxies)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        data_rows = []\n",
    "        table_rows = soup.select('ul.zwd_table.no_select li')[1:]  # Skip the first row if it contains headers\n",
    "        for row in table_rows:\n",
    "            columns = [col.get_text(strip=True) for col in row.find_all('p')]\n",
    "            if len(columns) >= 2:\n",
    "                date, price = columns[0], columns[1]\n",
    "                data_rows.append([\n",
    "                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # QueryTimestamp\n",
    "                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # TableFetchTimestamp\n",
    "                    price,  # Price from the page\n",
    "                    website_config['currency'],  # Currency from config\n",
    "                    'N/A', 'N/A', 'N/A', 'N/A', 'N/A',  # Other values as N/A or placeholders\n",
    "                    website_config['product_name'],  # ProductName from config\n",
    "                    website_config['type'],  # Type from config\n",
    "                    website_config['WebsiteName'],  # WebsiteName from config\n",
    "                    usd_inr_rate,  # USD_INR rate from fetched data\n",
    "                    rmb_inr_rate,  # RMB_INR rate from fetched data\n",
    "                ])\n",
    "\n",
    "        # Construct DataFrame\n",
    "        df = pd.DataFrame(data_rows, columns=[\n",
    "            'QueryTimestamp', 'TableFetchTimestamp', 'Price', 'Currency', 'Open_', 'High', 'Low',\n",
    "            'Volume', 'ChgPerc', 'ProductName', 'Type', 'WebsiteName', 'USD_INR', 'RMB_INR'\n",
    "        ])\n",
    "\n",
    "        # Generate IdentifierKey\n",
    "        df['IdentifierKey'] = df.apply(\n",
    "            lambda x: f\"{x['TableFetchTimestamp']}_{x['ProductName']}_{x['WebsiteName']}\", axis=1\n",
    "        )\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data for {website_config['product_name']}: {e}\")\n",
    "        return pd.DataFrame(columns=[\n",
    "            'QueryTimestamp', 'TableFetchTimestamp', 'Price', 'Currency', 'Open_', 'High', 'Low',\n",
    "            'Volume', 'ChgPerc', 'ProductName', 'Type', 'WebsiteName', 'USD_INR', 'RMB_INR', 'IdentifierKey'\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No element found for the selector table.common-table.medium.js-table tr:nth-of-type(2) td:nth-of-type(2) at URL https://in.investing.com/currencies/usd-inr-historical-data\n",
      "No element found for the selector table.common-table.medium.js-table tr:nth-of-type(2) td:nth-of-type(2) at URL https://in.investing.com/currencies/cny-inr-historical-data\n",
      "Failed to fetch conversion rates. Exiting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fetch_conversion_rate(url, selector):\n",
    "    \"\"\"Fetch the latest conversion rate from a given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, proxies=proxies)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        rate_cell = soup.select_one(selector)\n",
    "        if rate_cell:\n",
    "            rate_text = rate_cell.get_text(strip=True).replace(',', '')\n",
    "            return float(rate_text)\n",
    "        else:\n",
    "            print(f\"No element found for the selector {selector} at URL {url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching the conversion rate from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def run():\n",
    "    # Define the selectors for the conversion rates on the Investing.com website\n",
    "    usd_inr_selector = 'table.common-table.medium.js-table tr:nth-of-type(2) td:nth-of-type(2)'\n",
    "    rmb_inr_selector = 'table.common-table.medium.js-table tr:nth-of-type(2) td:nth-of-type(2)'\n",
    "    \n",
    "    # Fetch the conversion rates using the defined selectors\n",
    "    usd_inr_rate = fetch_conversion_rate(\"https://in.investing.com/currencies/usd-inr-historical-data\", usd_inr_selector)\n",
    "    rmb_inr_rate = fetch_conversion_rate(\"https://in.investing.com/currencies/cny-inr-historical-data\", rmb_inr_selector)\n",
    "\n",
    "    # Make sure the rates were fetched successfully, otherwise set them to None or handle as needed\n",
    "    if usd_inr_rate is None or rmb_inr_rate is None:\n",
    "        print(\"Failed to fetch conversion rates. Exiting.\")\n",
    "        return  # or you can set a default value or handle this case as needed\n",
    "\n",
    "    combined_data = []\n",
    "    for website in config['websites']:\n",
    "        df = fetch_commodity_data(website, usd_inr_rate, rmb_inr_rate)\n",
    "        if not df.empty:\n",
    "            combined_data.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one if any data was fetched\n",
    "    if combined_data:\n",
    "        combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "        combined_csv_filename = \"combined_commodities_data.csv\"\n",
    "        combined_df.to_csv(combined_csv_filename, index=False)\n",
    "        print(f\"Combined data saved to {combined_csv_filename}.\")\n",
    "    else:\n",
    "        print(\"No data fetched.\")\n",
    "\n",
    "# The entry point of the script\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_conversion_rate(url, selector):\n",
    "    \"\"\"Fetch the latest conversion rate from a given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, proxies=proxies)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        rate_cell = soup.select_one(selector)\n",
    "        if rate_cell:\n",
    "            rate_text = rate_cell.get_text(strip=True).replace(',', '')\n",
    "            return float(rate_text)\n",
    "        else:\n",
    "            print(f\"No element found for the selector {selector} at URL {url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching the conversion rate from {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
